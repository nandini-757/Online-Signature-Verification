{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1f17d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cleaned and saved 1600 valid signature files.\n",
      "âœ… Extracted 1600 samples\n",
      "   Genuine: 800 | Forged: 800\n",
      "\n",
      "âœ… PHYSICS-BASED RF TRAINED\n",
      "Accuracy: 0.76875\n",
      "\n",
      "Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.78       166\n",
      "           1       0.76      0.75      0.76       154\n",
      "\n",
      "    accuracy                           0.77       320\n",
      "   macro avg       0.77      0.77      0.77       320\n",
      "weighted avg       0.77      0.77      0.77       320\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[130  36]\n",
      " [ 38 116]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import re\n",
    "\n",
    "# ============================================================\n",
    "# STEP 1: CLEAN FILES\n",
    "# ============================================================\n",
    "def clean_task1_dataset(raw_folder, clean_folder):\n",
    "    os.makedirs(clean_folder, exist_ok=True)\n",
    "    all_files = glob.glob(f\"{raw_folder}/*.txt\")\n",
    "    valid = 0\n",
    "\n",
    "    for f in all_files:\n",
    "        try:\n",
    "            with open(f, 'r', errors='ignore') as file:\n",
    "                lines = file.readlines()\n",
    "\n",
    "            if not lines:\n",
    "                continue\n",
    "\n",
    "            lines = lines[1:]  # skip point count\n",
    "            lines = [ln for ln in lines if ln.strip()]\n",
    "            if len(lines) < 6:\n",
    "                continue\n",
    "\n",
    "            clean_path = f.replace(raw_folder, clean_folder)\n",
    "            os.makedirs(os.path.dirname(clean_path), exist_ok=True)\n",
    "\n",
    "            with open(clean_path, 'w') as wf:\n",
    "                wf.writelines(lines)\n",
    "\n",
    "            valid += 1\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    print(f\"âœ… Cleaned and saved {valid} valid signature files.\")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 2: FEATURE EXTRACTION\n",
    "# ============================================================\n",
    "def extract_features_from_signature(df):\n",
    "    try:\n",
    "        df = df.iloc[:, :3].copy()\n",
    "        df.columns = [\"X\", \"Y\", \"T\"]\n",
    "        df = df.apply(pd.to_numeric, errors=\"coerce\").dropna()\n",
    "\n",
    "        if len(df) < 6:\n",
    "            return None\n",
    "\n",
    "        dx = np.diff(df[\"X\"])\n",
    "        dy = np.diff(df[\"Y\"])\n",
    "        dt = np.diff(df[\"T\"])\n",
    "        dt[dt == 0] = 1\n",
    "\n",
    "        # Velocity\n",
    "        v = np.sqrt(dx**2 + dy**2) / dt\n",
    "\n",
    "        # Acceleration\n",
    "        a = np.diff(v) / dt[1:]\n",
    "\n",
    "        # Direction\n",
    "        theta = np.arctan2(dy, dx)\n",
    "\n",
    "        # Angular velocity\n",
    "        w = np.diff(theta) / dt[1:]\n",
    "\n",
    "        # Angular acceleration\n",
    "        alpha = np.diff(w) / dt[2:]\n",
    "\n",
    "        # Simulated pressure\n",
    "        pressure = 1 / (v + 1e-6)\n",
    "\n",
    "        # Torque proxy\n",
    "        tau = pressure * v\n",
    "\n",
    "        def stats(arr):\n",
    "            return np.mean(arr), np.std(arr), np.max(arr)\n",
    "\n",
    "        stroke_count = np.sum(dt > np.percentile(dt, 90)) + 1\n",
    "        direction_changes = np.sum(np.abs(np.diff(theta)) > np.pi / 4)\n",
    "\n",
    "        return {\n",
    "            \"v_mean\": stats(v)[0],\n",
    "            \"v_std\": stats(v)[1],\n",
    "            \"v_max\": stats(v)[2],\n",
    "\n",
    "            \"a_mean\": stats(a)[0],\n",
    "            \"a_std\": stats(a)[1],\n",
    "            \"a_max\": stats(a)[2],\n",
    "\n",
    "            \"w_mean\": stats(w)[0],\n",
    "            \"w_std\": stats(w)[1],\n",
    "\n",
    "            \"alpha_mean\": stats(alpha)[0],\n",
    "            \"alpha_std\": stats(alpha)[1],\n",
    "\n",
    "            \"tau_mean\": stats(tau)[0],\n",
    "            \"tau_std\": stats(tau)[1],\n",
    "            \"tau_max\": stats(tau)[2],\n",
    "\n",
    "            \"stroke_count\": stroke_count,\n",
    "            \"direction_changes\": direction_changes\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 3: BUILD DATASET WITH CORRECT LABELS\n",
    "# ============================================================\n",
    "def build_training_dataset(clean_folder):\n",
    "    files = glob.glob(f\"{clean_folder}/*.txt\")\n",
    "    rows = []\n",
    "    genuine_count = forgery_count = 0\n",
    "\n",
    "    for f in files:\n",
    "        try:\n",
    "            fname = os.path.basename(f)\n",
    "            match = re.match(r'U(\\d+)S(\\d+)\\.txt', fname, re.IGNORECASE)\n",
    "            if not match:\n",
    "                continue\n",
    "\n",
    "            instance_id = int(match.group(2))\n",
    "\n",
    "            df = pd.read_csv(f, sep=r\"\\s+\", header=None)\n",
    "            features = extract_features_from_signature(df)\n",
    "\n",
    "            if features:\n",
    "                if 1 <= instance_id <= 20:\n",
    "                    features[\"label\"] = 1\n",
    "                    genuine_count += 1\n",
    "                else:\n",
    "                    features[\"label\"] = 0\n",
    "                    forgery_count += 1\n",
    "\n",
    "                rows.append(features)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    feature_df = pd.DataFrame(rows)\n",
    "    feature_df.to_csv(\"physics_signature_features.csv\", index=False)\n",
    "\n",
    "    print(f\"âœ… Extracted {len(feature_df)} samples\")\n",
    "    print(f\"   Genuine: {genuine_count} | Forged: {forgery_count}\")\n",
    "\n",
    "    return feature_df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# STEP 4: TRAIN RANDOM FOREST\n",
    "# ============================================================\n",
    "def train_signature_model(df):\n",
    "    if df.empty or len(df[\"label\"].unique()) < 2:\n",
    "        print(\"âš  Not enough data to train.\")\n",
    "        return\n",
    "\n",
    "    X = df.drop(\"label\", axis=1)\n",
    "    y = df[\"label\"]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=12,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    print(\"\\nâœ… PHYSICS-BASED RF TRAINED\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "    print(\"\\nReport:\\n\", classification_report(y_test, preds))\n",
    "    print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, preds))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================\n",
    "RAW_PATH = r\"C:\\Users\\Nandini\\osv-hybrid\\notebooks\\Task1\"\n",
    "CLEAN_PATH = r\"C:\\Users\\Nandini\\osv-hybrid\\notebooks\\Task1_clean\"\n",
    "\n",
    "clean_task1_dataset(RAW_PATH, CLEAN_PATH)\n",
    "df = build_training_dataset(CLEAN_PATH)\n",
    "train_signature_model(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589fe22c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape (1147917952.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 17\u001b[1;36m\u001b[0m\n\u001b[1;33m    DATASET_PATH = \"D:\\Users\\Nandini\\Downloads\\archive\"   # CHANGE THIS\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# STATIC SIGNATURE VERIFICATION - SIAMESE CNN (SINGLE FILE)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "\n",
    "DATASET_PATH = r\"\"   # CHANGE THIS\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "\n",
    "# ============================================================\n",
    "# IMAGE LOADER\n",
    "# ============================================================\n",
    "\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img = img / 255.0\n",
    "    return img.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "# ============================================================\n",
    "# PAIR GENERATOR\n",
    "# ============================================================\n",
    "\n",
    "def generate_pairs(root):\n",
    "    users = os.listdir(root)\n",
    "    pairs, labels = [], []\n",
    "\n",
    "    for user in users:\n",
    "        user_path = os.path.join(root, user)\n",
    "        imgs = os.listdir(user_path)\n",
    "\n",
    "        for _ in range(5):\n",
    "            # Genuine pair\n",
    "            i1, i2 = random.sample(imgs, 2)\n",
    "            pairs.append((os.path.join(user_path, i1),\n",
    "                          os.path.join(user_path, i2)))\n",
    "            labels.append(1)\n",
    "\n",
    "            # Forged pair\n",
    "            other = random.choice([u for u in users if u != user])\n",
    "            other_img = random.choice(os.listdir(os.path.join(root, other)))\n",
    "            pairs.append((os.path.join(user_path, i1),\n",
    "                          os.path.join(root, other, other_img)))\n",
    "            labels.append(0)\n",
    "\n",
    "    return pairs, labels\n",
    "\n",
    "pairs, labels = generate_pairs(DATASET_PATH)\n",
    "\n",
    "# ============================================================\n",
    "# DATASET PREPARATION\n",
    "# ============================================================\n",
    "\n",
    "X1, X2, y = [], [], []\n",
    "\n",
    "for (p1, p2), label in zip(pairs, labels):\n",
    "    X1.append(load_image(p1))\n",
    "    X2.append(load_image(p2))\n",
    "    y.append(label)\n",
    "\n",
    "X1 = np.array(X1)\n",
    "X2 = np.array(X2)\n",
    "y = np.array(y)\n",
    "\n",
    "# ============================================================\n",
    "# EMBEDDING NETWORK (MobileNet)\n",
    "# ============================================================\n",
    "\n",
    "def embedding_network():\n",
    "    base = MobileNetV2(\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 1),\n",
    "        include_top=False,\n",
    "        weights=None\n",
    "    )\n",
    "\n",
    "    x = base.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Lambda(lambda x: K.l2_normalize(x, axis=1))(x)\n",
    "\n",
    "    return models.Model(base.input, x)\n",
    "\n",
    "# ============================================================\n",
    "# SIAMESE MODEL\n",
    "# ============================================================\n",
    "\n",
    "def euclidean_distance(v):\n",
    "    a, b = v\n",
    "    return K.sqrt(K.sum(K.square(a - b), axis=1, keepdims=True))\n",
    "\n",
    "input_a = layers.Input((IMG_SIZE, IMG_SIZE, 1))\n",
    "input_b = layers.Input((IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "embed = embedding_network()\n",
    "\n",
    "ea = embed(input_a)\n",
    "eb = embed(input_b)\n",
    "\n",
    "dist = layers.Lambda(euclidean_distance)([ea, eb])\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(dist)\n",
    "\n",
    "model = models.Model([input_a, input_b], output)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN\n",
    "# ============================================================\n",
    "\n",
    "model.fit([X1, X2], y, batch_size=BATCH_SIZE, epochs=EPOCHS)\n",
    "\n",
    "model.save(\"siamese_static_model.h5\")\n",
    "\n",
    "print(\"âœ… STATIC SIAMESE CNN TRAINED SUCCESSFULLY\")\n",
    "\n",
    "# ============================================================\n",
    "# EMBEDDING COMPARISON FUNCTION (INFERENCE)\n",
    "# ============================================================\n",
    "\n",
    "def compare_signatures(img1, img2):\n",
    "    embed_model = embedding_network()\n",
    "    embed_model.set_weights(model.get_weights())\n",
    "\n",
    "    e1 = embed_model(load_image(img1).reshape(1, IMG_SIZE, IMG_SIZE, 1))\n",
    "    e2 = embed_model(load_image(img2).reshape(1, IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "    return np.linalg.norm(e1 - e2)\n",
    "\n",
    "# Example:\n",
    "# score = compare_signatures(\"sig1.png\", \"sig2.png\")\n",
    "# print(\"Similarity Distance:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646fbcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (4800, 96, 96, 1) (4800, 96, 96, 1) (4800,)\n",
      "Epoch 1/3\n",
      "\u001b[1m150/150\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 322ms/step - loss: 0.5000\n",
      "Epoch 2/3\n",
      "\u001b[1m150/150\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 223ms/step - loss: 0.5000\n",
      "Epoch 3/3\n",
      "\u001b[1m150/150\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 201ms/step - loss: 0.5000\n",
      "âœ… Siamese CNN trained successfully\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Embedding model saved as static_embedding_model.h5\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SIAMESE CNN FOR GPDS (FINAL - FULL UPDATED CODE)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import random\n",
    "#import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "GPDS_TRAIN_PATH = r\"C:\\Users\\Nandini\\osv-hybrid\\training\\New folder (10)\\train\"   \n",
    "IMG_SIZE = 96\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# IMAGE PREPROCESSING FUNCTION\n",
    "# ============================================================\n",
    "\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img = img / 255.0\n",
    "    return img.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "# ============================================================\n",
    "# LOAD FILES\n",
    "# ============================================================\n",
    "\n",
    "genuine_path = os.path.join(GPDS_TRAIN_PATH, \"genuine\")\n",
    "forge_path   = os.path.join(GPDS_TRAIN_PATH, \"forge\")\n",
    "\n",
    "genuine_files = os.listdir(genuine_path)\n",
    "forge_files   = os.listdir(forge_path)\n",
    "\n",
    "# ============================================================\n",
    "# USER ID EXTRACTION (FOR c-001-01, cf-001-01 FORMAT)\n",
    "# ============================================================\n",
    "\n",
    "def get_uid(filename):\n",
    "    match = re.search(r'-(\\d{3})-', filename)\n",
    "    return match.group(1) if match else None\n",
    "\n",
    "# ============================================================\n",
    "# GENERATE SIAMESE PAIRS\n",
    "# ============================================================\n",
    "\n",
    "X1, X2, y = [], [], []\n",
    "\n",
    "for g in genuine_files:\n",
    "    uid = get_uid(g)\n",
    "    if uid is None:\n",
    "        continue\n",
    "\n",
    "    same_user_genuine = [\n",
    "        f for f in genuine_files\n",
    "        if get_uid(f) == uid and f != g\n",
    "    ]\n",
    "\n",
    "    same_user_forged = [\n",
    "        f for f in forge_files\n",
    "        if get_uid(f) == uid\n",
    "    ]\n",
    "\n",
    "    if not same_user_genuine or not same_user_forged:\n",
    "        continue\n",
    "\n",
    "    # -------- GENUINE PAIR --------\n",
    "    g2 = random.choice(same_user_genuine)\n",
    "    X1.append(load_image(os.path.join(genuine_path, g)))\n",
    "    X2.append(load_image(os.path.join(genuine_path, g2)))\n",
    "    y.append(1)\n",
    "\n",
    "    # -------- FORGED PAIR --------\n",
    "    f2 = random.choice(same_user_forged)\n",
    "    X1.append(load_image(os.path.join(genuine_path, g)))\n",
    "    X2.append(load_image(os.path.join(forge_path, f2)))\n",
    "    y.append(0)\n",
    "\n",
    "X1 = np.array(X1)\n",
    "X2 = np.array(X2)\n",
    "y  = np.array(y).astype(\"float32\")\n",
    "\n",
    "print(\"Shapes:\", X1.shape, X2.shape, y.shape)\n",
    "\n",
    "# ============================================================\n",
    "# EMBEDDING MODEL (MOBILENET BASED)\n",
    "# ============================================================\n",
    "\n",
    "def embedding_model():\n",
    "    base = MobileNetV2(\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 1),\n",
    "        include_top=False,\n",
    "        weights=None\n",
    "    )\n",
    "    for layer in base.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    class L2Normalize(layers.Layer):\n",
    "        def call(self, inputs):\n",
    "            return tf.math.l2_normalize(inputs, axis=1)\n",
    "    x = L2Normalize()(x)\n",
    "\n",
    "\n",
    "    return models.Model(base.input, x)\n",
    "\n",
    "# ============================================================\n",
    "# SIAMESE NETWORK (DISTANCE OUTPUT)\n",
    "# ============================================================\n",
    "\n",
    "# ============================================================\n",
    "# CUSTOM DISTANCE LAYER (KERAS 3 SAFE)\n",
    "# ============================================================\n",
    "\n",
    "class EuclideanDistance(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        a, b = inputs\n",
    "        return tf.sqrt(tf.reduce_sum(tf.square(a - b), axis=1, keepdims=True))\n",
    "\n",
    "\n",
    "input_a = layers.Input((IMG_SIZE, IMG_SIZE, 1))\n",
    "input_b = layers.Input((IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "embed = embedding_model()\n",
    "\n",
    "ea = embed(input_a)\n",
    "eb = embed(input_b)\n",
    "\n",
    "distance = EuclideanDistance()([ea, eb])\n",
    "\n",
    "siamese = models.Model([input_a, input_b], distance)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CONTRASTIVE LOSS (CORRECT FOR SIAMESE)\n",
    "# ============================================================\n",
    "\n",
    "def contrastive_loss(y_true, d):\n",
    "    margin = 1.0\n",
    "    return K.mean(\n",
    "        y_true * K.square(d) +\n",
    "        (1 - y_true) * K.square(K.maximum(margin - d, 0))\n",
    "    )\n",
    "\n",
    "siamese.compile(\n",
    "    loss=contrastive_loss,\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4)\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN MODEL\n",
    "# ============================================================\n",
    "\n",
    "siamese.fit(\n",
    "    [X1, X2],\n",
    "    y,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "print(\"âœ… Siamese CNN trained successfully\")\n",
    "\n",
    "# ============================================================\n",
    "# SAVE EMBEDDING MODEL AS .PKL (BACKEND USE)\n",
    "# ============================================================\n",
    "\n",
    "# build embedding network\n",
    "embedding_net = embedding_model()\n",
    "\n",
    "# copy weights\n",
    "embedding_net.set_weights(embed.get_weights())\n",
    "\n",
    "# âœ… SAVE AS .h5\n",
    "embedding_net.save(\"static_embedding_model.h5\")\n",
    "\n",
    "print(\"âœ… Embedding model saved as static_embedding_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e51fdede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs: (4800, 96, 96, 1) (4800, 96, 96, 1)\n",
      "WARNING:tensorflow:From C:\\Users\\Nandini\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:232: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m150/150\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 99ms/step - loss: 0.5000\n",
      "Epoch 2/10\n",
      "\u001b[1m150/150\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 130ms/step - loss: 0.5000\n",
      "Epoch 3/10\n",
      "\u001b[1m150/150\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 130ms/step - loss: 0.5000\n",
      "Epoch 4/10\n",
      "\u001b[1m150/150\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 138ms/step - loss: 0.5000\n",
      "Epoch 5/10\n",
      "\u001b[1m150/150\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 128ms/step - loss: 0.5000\n",
      "Epoch 6/10\n",
      "\u001b[1m150/150\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 130ms/step - loss: 0.5000\n",
      "Epoch 7/10\n",
      "\u001b[1m150/150\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 133ms/step - loss: 0.5000\n",
      "Epoch 8/10\n",
      "\u001b[1m150/150\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 108ms/step - loss: 0.5000\n",
      "Epoch 9/10\n",
      "\u001b[1m150/150\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 90ms/step - loss: 0.5000\n",
      "Epoch 10/10\n",
      "\u001b[1m150/150\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 96ms/step - loss: 0.5000\n",
      "âœ… Siamese trained\n",
      "âœ… Embedding model saved (static_embedding_model.keras)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# SIAMESE CNN FOR GPDS (KERAS 3 SAFE - FINAL)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, backend as K\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "\n",
    "GPDS_TRAIN_PATH = r\"C:\\Users\\Nandini\\osv-hybrid\\training\\New folder (10)\\train\"\n",
    "IMG_SIZE = 96\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# ============================================================\n",
    "# IMAGE LOADER\n",
    "# ============================================================\n",
    "\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img = img / 255.0\n",
    "    return img.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "\n",
    "# ============================================================\n",
    "# LOAD FILES\n",
    "# ============================================================\n",
    "\n",
    "genuine_path = os.path.join(GPDS_TRAIN_PATH, \"genuine\")\n",
    "forge_path   = os.path.join(GPDS_TRAIN_PATH, \"forge\")\n",
    "\n",
    "genuine_files = os.listdir(genuine_path)\n",
    "forge_files   = os.listdir(forge_path)\n",
    "\n",
    "def get_uid(filename):\n",
    "    m = re.search(r'-(\\d{3})-', filename)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "# ============================================================\n",
    "# BUILD PAIRS\n",
    "# ============================================================\n",
    "\n",
    "X1, X2, y = [], [], []\n",
    "\n",
    "for g in genuine_files:\n",
    "    uid = get_uid(g)\n",
    "    if uid is None:\n",
    "        continue\n",
    "\n",
    "    pos = [f for f in genuine_files if get_uid(f) == uid and f != g]\n",
    "    neg = [f for f in forge_files if get_uid(f) == uid]\n",
    "\n",
    "    if not pos or not neg:\n",
    "        continue\n",
    "\n",
    "    g2 = random.choice(pos)\n",
    "    f2 = random.choice(neg)\n",
    "\n",
    "    X1.append(load_image(os.path.join(genuine_path, g)))\n",
    "    X2.append(load_image(os.path.join(genuine_path, g2)))\n",
    "    y.append(1)\n",
    "\n",
    "    X1.append(load_image(os.path.join(genuine_path, g)))\n",
    "    X2.append(load_image(os.path.join(forge_path, f2)))\n",
    "    y.append(0)\n",
    "\n",
    "X1 = np.array(X1)\n",
    "X2 = np.array(X2)\n",
    "y  = np.array(y).astype(\"float32\")\n",
    "\n",
    "print(\"Pairs:\", X1.shape, X2.shape)\n",
    "\n",
    "# ============================================================\n",
    "# EMBEDDING MODEL (NO CUSTOM LAYERS)\n",
    "# ============================================================\n",
    "\n",
    "def embedding_model():\n",
    "    base = MobileNetV2(\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 1),\n",
    "        include_top=False,\n",
    "        weights=None\n",
    "    )\n",
    "    for layer in base.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    x = base.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "    return models.Model(base.input, x)\n",
    "\n",
    "# ============================================================\n",
    "# SIAMESE NETWORK (TRAINING ONLY)\n",
    "# ============================================================\n",
    "\n",
    "def euclidean_distance(v):\n",
    "    a, b = v\n",
    "    return K.sqrt(K.sum(K.square(a - b), axis=1, keepdims=True))\n",
    "\n",
    "input_a = layers.Input((IMG_SIZE, IMG_SIZE, 1))\n",
    "input_b = layers.Input((IMG_SIZE, IMG_SIZE, 1))\n",
    "\n",
    "embed = embedding_model()\n",
    "\n",
    "ea = embed(input_a)\n",
    "eb = embed(input_b)\n",
    "\n",
    "distance = layers.Lambda(euclidean_distance)([ea, eb])\n",
    "\n",
    "siamese = models.Model([input_a, input_b], distance)\n",
    "\n",
    "def contrastive_loss(y_true, d):\n",
    "    margin = 1.0\n",
    "    return K.mean(\n",
    "        y_true * K.square(d) +\n",
    "        (1 - y_true) * K.square(K.maximum(margin - d, 0))\n",
    "    )\n",
    "\n",
    "siamese.compile(\n",
    "    loss=contrastive_loss,\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-4)\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# TRAIN\n",
    "# ============================================================\n",
    "\n",
    "siamese.fit(\n",
    "    [X1, X2],\n",
    "    y,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "print(\"âœ… Siamese trained\")\n",
    "\n",
    "# ============================================================\n",
    "# SAVE EMBEDDING MODEL (PRODUCTION)\n",
    "# ============================================================\n",
    "\n",
    "embedding_net = embedding_model()\n",
    "embedding_net.set_weights(embed.get_weights())\n",
    "\n",
    "# ðŸ”¥ SAVE AS .keras (NO ERRORS EVER)\n",
    "embedding_net.save(\"static_embedding_model.keras\")\n",
    "\n",
    "print(\"âœ… Embedding model saved (static_embedding_model.keras)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
